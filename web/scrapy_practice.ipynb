{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapy : 스크래피는 웹사이트에서 데이터 추출을 위한 오픈소스 프레임워크\n",
    "\n",
    "## css selector가 아닌 xpath를 이용하여 웹 페이지의 html 엘리먼트를 선택한 객체를 생성가능\n",
    "## scarpy 기본문법, scrapy 2가지로 가능하다 shell이랑 jupyter notebook에서!\n",
    "## scrapy project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## xpath 문법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//*[@id=\"content\"]/div[1]/div[1]/div[3]/ul/li[1]/dl/dt/a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`//` : 가장 상위 엘리먼트\n",
    "`//*` : 상위에서 하위 모든 것을 검색\n",
    "`/` : 하위로 한 단계 내려감\n",
    "`*` : 하위의 모든 것\n",
    "`[@key=value]` : @attribute 속성 값을 의미\n",
    "`div` : 엘리먼트 이름\n",
    "`[number]` : number 번째의 엘리먼트, 1부터 시작된다.\n",
    "`not(조건)` : 조건이 아닌 엘리먼트\n",
    "`.` : 현재 엘리먼트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. scrapy shell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrapy shell 이용해서 네이버 키워드 데이터 수집, 다음 키워드 데이터 수집, gmarket 베스트 상품 데이터 수집 해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 네이버 키워드 데이터 수집"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cmd 창에 `$ scrapy shell \"url\"` 작성해서 scrapy shell을 연다.\n",
    "- 열린 scrapy shell에서 `response.xpath('')`를 이용해 데이터를 스크래핑한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 실시간 검색 1위 xpath 객체 가져오기\n",
    "# 네이버 실시간 검색 20개 xpath 객체 가져오기\n",
    "# xpath의 text() 를 이용하여 xpath 객체의 text 데이터 추출하기\n",
    "# .extract() 함수를 이용하여 xpath에서 추출된 text 데이터 리스트로 추출하기\n",
    "# 검색어 데이터만 가져오기\n",
    "# xpath의 .을 이용해서 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapy shell \"https://naver.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response.xpath('//*[@id=\"PM_ID_ct\"]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다음 실시간 검색어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스크래피 쉘을 이용하여 다음 페이지 연결하기\n",
    "# 다음의 실시간 검색어 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapy shell \"http://daum.net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response.xpath('//*[@id=\"mArticle\"]/div[2]/div[2]/div[2]/div[1]/ol/li/div/div[1]/span[2]/a/text()').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gmarket 베스트 아이템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스크래피 쉘을 이용하여 gmarket 베스트 페이지 연결하기\n",
    "# 베스트 200 아이템 제목 데이터 가져오기\n",
    "# li 엘리먼트에서 class가 first가 데이터만 가져오기\n",
    "# li 엘리먼트에서 class가 first가 아닌 데이터만 가져오기\n",
    "# gmartket 베스트 아이템 링크 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 베스트 200 아이템 제목 데이터 가져오기\n",
    "# response.xpath('//*[@id=\"gBestWrap\"]/div/div[3]/div[2]/ul/li/a/text()').extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# li 엘리먼트에서 class가 first가 데이터만 가져오기\n",
    "# response.xpath('//*[@id=\"gBestWrap\"]/div/div[3]/div[2]/ul/li[@class=\"first\"]/a/text()').extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# li 엘리먼트에서 class가 first가 아닌 데이터만 가져오기\n",
    "# response.xpath('//*[@id=\"gBestWrap\"]/div/div[3]/div[2]/ul/li[not(@class=\"first\")]/a/text()').extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gmartket 베스트 아이템 링크 가져오기\n",
    "# response.xpath('//*[@id=\"gBestWrap\"]/div/div[3]/div[2]/ul/li[not(@class=\"first\")]/a/@href').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from scrapy.http import TextResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹페이지 연결\n",
    "req = requests.get('https://www.naver.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response 객체 생성\n",
    "response = TextResponse(req.url, body=req.text, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['고두심',\n",
       " '황교익',\n",
       " '두니아',\n",
       " '일본 세네갈',\n",
       " '잉글랜드 파나마',\n",
       " '한국 독일',\n",
       " '로또812회당첨번호',\n",
       " '고두심나이',\n",
       " '강경준 바베큐',\n",
       " '다뉴브강',\n",
       " '독일 스웨덴',\n",
       " '다뉴브강 역사',\n",
       " '다뉴브강 신발',\n",
       " '강진',\n",
       " '강진 실종 여고생',\n",
       " '이채영',\n",
       " '폴란드 콜롬비아',\n",
       " '강진 여고생',\n",
       " '같이 살래요',\n",
       " '전지적 참견 시점']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.xpath('//*[@id=\"PM_ID_ct\"]/div[1]/div[2]/div[2]/div[1]/div/ul/li/a/span[2]/text()').extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
